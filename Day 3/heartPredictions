{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day3_NeuralNetworks.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.9 64-bit"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9"
    },
    "metadata": {
      "interpreter": {
        "hash": "7f8c79caef6f500d10f1d53b5233fd35aa3fbbd3a39d10048919692e9c705d27"
      }
    },
    "interpreter": {
      "hash": "7f8c79caef6f500d10f1d53b5233fd35aa3fbbd3a39d10048919692e9c705d27"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y29U8oRAKG6K"
      },
      "source": [
        "**Step 1: Import Python Packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1IVlRgyKQbC"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eW8BK7uuKwB5"
      },
      "source": [
        "**Step 2: Import the Dataset**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wD1Z5T1dK6PJ"
      },
      "source": [
        "data = pd.read_csv(\"heart.csv\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "HdB4y7J-Sm8K",
        "outputId": "e1606462-38a1-4a7b-c531-f245fc92227c"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
              "0   63    1   3     145   233    1        0       150     0      2.3    0   \n",
              "1   37    1   2     130   250    0        1       187     0      3.5    0   \n",
              "2   41    0   1     130   204    0        0       172     0      1.4    2   \n",
              "3   56    1   1     120   236    0        1       178     0      0.8    2   \n",
              "4   57    0   0     120   354    0        1       163     1      0.6    2   \n",
              "\n",
              "   caa  thall  output  \n",
              "0    0      1       1  \n",
              "1    0      2       1  \n",
              "2    0      2       1  \n",
              "3    0      2       1  \n",
              "4    0      2       1  "
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trtbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalachh</th>\n      <th>exng</th>\n      <th>oldpeak</th>\n      <th>slp</th>\n      <th>caa</th>\n      <th>thall</th>\n      <th>output</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>63</td>\n      <td>1</td>\n      <td>3</td>\n      <td>145</td>\n      <td>233</td>\n      <td>1</td>\n      <td>0</td>\n      <td>150</td>\n      <td>0</td>\n      <td>2.3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>37</td>\n      <td>1</td>\n      <td>2</td>\n      <td>130</td>\n      <td>250</td>\n      <td>0</td>\n      <td>1</td>\n      <td>187</td>\n      <td>0</td>\n      <td>3.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>41</td>\n      <td>0</td>\n      <td>1</td>\n      <td>130</td>\n      <td>204</td>\n      <td>0</td>\n      <td>0</td>\n      <td>172</td>\n      <td>0</td>\n      <td>1.4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>56</td>\n      <td>1</td>\n      <td>1</td>\n      <td>120</td>\n      <td>236</td>\n      <td>0</td>\n      <td>1</td>\n      <td>178</td>\n      <td>0</td>\n      <td>0.8</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>57</td>\n      <td>0</td>\n      <td>0</td>\n      <td>120</td>\n      <td>354</td>\n      <td>0</td>\n      <td>1</td>\n      <td>163</td>\n      <td>1</td>\n      <td>0.6</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "d_XmX8KFimiR",
        "outputId": "ea160873-9b86-47e6-c1cc-d515c6ae56e5"
      },
      "source": [
        "# remove unnecessary columns\n",
        "data = data.drop('restecg',axis=1)\n",
        "data = data.drop('slp',axis=1)\n",
        "data = data.drop('thall',axis=1)\n",
        "data = data.drop('oldpeak',axis=1)\n",
        "data.tail()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     age  sex  cp  trtbps  chol  fbs  thalachh  exng  caa  output\n",
              "298   57    0   0     140   241    0       123     1    0       0\n",
              "299   45    1   3     110   264    0       132     0    0       0\n",
              "300   68    1   0     144   193    1       141     0    2       0\n",
              "301   57    1   0     130   131    0       115     1    1       0\n",
              "302   57    0   1     130   236    0       174     0    1       0"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trtbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>thalachh</th>\n      <th>exng</th>\n      <th>caa</th>\n      <th>output</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>298</th>\n      <td>57</td>\n      <td>0</td>\n      <td>0</td>\n      <td>140</td>\n      <td>241</td>\n      <td>0</td>\n      <td>123</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>45</td>\n      <td>1</td>\n      <td>3</td>\n      <td>110</td>\n      <td>264</td>\n      <td>0</td>\n      <td>132</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>300</th>\n      <td>68</td>\n      <td>1</td>\n      <td>0</td>\n      <td>144</td>\n      <td>193</td>\n      <td>1</td>\n      <td>141</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>301</th>\n      <td>57</td>\n      <td>1</td>\n      <td>0</td>\n      <td>130</td>\n      <td>131</td>\n      <td>0</td>\n      <td>115</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>57</td>\n      <td>0</td>\n      <td>1</td>\n      <td>130</td>\n      <td>236</td>\n      <td>0</td>\n      <td>174</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7M_yXFGSti-"
      },
      "source": [
        "**Step 3: Split the Data into Test and Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U39irWPZSynZ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X=data.drop('output', axis=1)  \n",
        "y=data.output\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5VvKheiTafO"
      },
      "source": [
        "**Step 4: Create and Fit the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ney0KUTTgtQ"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=9, activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GR-3CCkiUYJw"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l17SXUanUYu4",
        "outputId": "bd1a469c-6675-4692-bc5e-23fc0429e1cb",
        "tags": [
          "outputPrepend"
        ]
      },
      "source": [
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200, batch_size=64)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_accuracy: 0.6813\n",
            "Epoch 60/200\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.9893 - accuracy: 0.6546 - val_loss: 0.6258 - val_accuracy: 0.6923\n",
            "Epoch 61/200\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.0886 - accuracy: 0.6385 - val_loss: 0.6413 - val_accuracy: 0.7143\n",
            "Epoch 62/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.0698 - accuracy: 0.6382 - val_loss: 0.6252 - val_accuracy: 0.7033\n",
            "Epoch 63/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.9222 - accuracy: 0.6453 - val_loss: 0.7608 - val_accuracy: 0.6813\n",
            "Epoch 64/200\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.9142 - accuracy: 0.6451 - val_loss: 0.6125 - val_accuracy: 0.6593\n",
            "Epoch 65/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.1342 - accuracy: 0.6213 - val_loss: 0.6351 - val_accuracy: 0.6593\n",
            "Epoch 66/200\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.7958 - accuracy: 0.6955 - val_loss: 0.6621 - val_accuracy: 0.6703\n",
            "Epoch 67/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.9371 - accuracy: 0.6010 - val_loss: 0.6474 - val_accuracy: 0.6813\n",
            "Epoch 68/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.8908 - accuracy: 0.6088 - val_loss: 0.6328 - val_accuracy: 0.6374\n",
            "Epoch 69/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.8753 - accuracy: 0.6557 - val_loss: 0.6736 - val_accuracy: 0.6703\n",
            "Epoch 70/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.9823 - accuracy: 0.6477 - val_loss: 0.6710 - val_accuracy: 0.6703\n",
            "Epoch 71/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.8573 - accuracy: 0.6328 - val_loss: 0.6837 - val_accuracy: 0.6813\n",
            "Epoch 72/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6916 - accuracy: 0.6817 - val_loss: 0.6228 - val_accuracy: 0.6703\n",
            "Epoch 73/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.7184 - accuracy: 0.6678 - val_loss: 0.7346 - val_accuracy: 0.6593\n",
            "Epoch 74/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.9622 - accuracy: 0.6202 - val_loss: 0.7441 - val_accuracy: 0.6374\n",
            "Epoch 75/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.9164 - accuracy: 0.6565 - val_loss: 0.6162 - val_accuracy: 0.6703\n",
            "Epoch 76/200\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.8030 - accuracy: 0.6562 - val_loss: 0.6357 - val_accuracy: 0.6703\n",
            "Epoch 77/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.8686 - accuracy: 0.6368 - val_loss: 0.6492 - val_accuracy: 0.6593\n",
            "Epoch 78/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.9037 - accuracy: 0.6099 - val_loss: 0.6374 - val_accuracy: 0.6593\n",
            "Epoch 79/200\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.7344 - accuracy: 0.7104 - val_loss: 0.6915 - val_accuracy: 0.6703\n",
            "Epoch 80/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.7620 - accuracy: 0.6427 - val_loss: 0.6132 - val_accuracy: 0.6813\n",
            "Epoch 81/200\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.7386 - accuracy: 0.6878 - val_loss: 0.6075 - val_accuracy: 0.6593\n",
            "Epoch 82/200\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.7409 - accuracy: 0.6802 - val_loss: 0.5897 - val_accuracy: 0.6703\n",
            "Epoch 83/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.8838 - accuracy: 0.6500 - val_loss: 0.7192 - val_accuracy: 0.6264\n",
            "Epoch 84/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.7195 - accuracy: 0.6565 - val_loss: 0.5817 - val_accuracy: 0.7033\n",
            "Epoch 85/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5755 - accuracy: 0.7290 - val_loss: 0.5717 - val_accuracy: 0.6813\n",
            "Epoch 86/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.7205 - accuracy: 0.6326 - val_loss: 0.6009 - val_accuracy: 0.6813\n",
            "Epoch 87/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6837 - accuracy: 0.6757 - val_loss: 0.5889 - val_accuracy: 0.6923\n",
            "Epoch 88/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.7815 - accuracy: 0.6674 - val_loss: 0.5658 - val_accuracy: 0.6923\n",
            "Epoch 89/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6994 - accuracy: 0.6728 - val_loss: 0.5878 - val_accuracy: 0.6813\n",
            "Epoch 90/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.7047 - accuracy: 0.6664 - val_loss: 0.5753 - val_accuracy: 0.6813\n",
            "Epoch 91/200\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.7580 - accuracy: 0.6455 - val_loss: 0.6096 - val_accuracy: 0.6703\n",
            "Epoch 92/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.7653 - accuracy: 0.6282 - val_loss: 0.6040 - val_accuracy: 0.7033\n",
            "Epoch 93/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.7487 - accuracy: 0.6554 - val_loss: 0.6007 - val_accuracy: 0.6813\n",
            "Epoch 94/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6954 - accuracy: 0.6639 - val_loss: 0.6555 - val_accuracy: 0.6374\n",
            "Epoch 95/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6412 - accuracy: 0.6639 - val_loss: 0.6373 - val_accuracy: 0.6593\n",
            "Epoch 96/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6579 - accuracy: 0.6772 - val_loss: 0.5933 - val_accuracy: 0.6923\n",
            "Epoch 97/200\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.6187 - accuracy: 0.6938 - val_loss: 0.5860 - val_accuracy: 0.6703\n",
            "Epoch 98/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.7413 - accuracy: 0.6807 - val_loss: 0.5641 - val_accuracy: 0.6813\n",
            "Epoch 99/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.7001 - accuracy: 0.6032 - val_loss: 0.5617 - val_accuracy: 0.7033\n",
            "Epoch 100/200\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.6204 - accuracy: 0.6940 - val_loss: 0.5846 - val_accuracy: 0.6593\n",
            "Epoch 101/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.7020 - accuracy: 0.6157 - val_loss: 0.6574 - val_accuracy: 0.6484\n",
            "Epoch 102/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.7133 - accuracy: 0.6659 - val_loss: 0.5653 - val_accuracy: 0.6813\n",
            "Epoch 103/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.7077 - accuracy: 0.6958 - val_loss: 0.5500 - val_accuracy: 0.7143\n",
            "Epoch 104/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.7147 - accuracy: 0.6736 - val_loss: 0.6002 - val_accuracy: 0.6703\n",
            "Epoch 105/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6746 - accuracy: 0.6414 - val_loss: 0.5744 - val_accuracy: 0.6374\n",
            "Epoch 106/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6648 - accuracy: 0.6768 - val_loss: 0.5762 - val_accuracy: 0.6923\n",
            "Epoch 107/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5952 - accuracy: 0.6996 - val_loss: 0.5747 - val_accuracy: 0.6703\n",
            "Epoch 108/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6307 - accuracy: 0.6711 - val_loss: 0.6022 - val_accuracy: 0.6703\n",
            "Epoch 109/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5958 - accuracy: 0.6908 - val_loss: 0.6005 - val_accuracy: 0.6593\n",
            "Epoch 110/200\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.5976 - accuracy: 0.6809 - val_loss: 0.5908 - val_accuracy: 0.6703\n",
            "Epoch 111/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6647 - accuracy: 0.6781 - val_loss: 0.5739 - val_accuracy: 0.7253\n",
            "Epoch 112/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6908 - accuracy: 0.6789 - val_loss: 0.5674 - val_accuracy: 0.7033\n",
            "Epoch 113/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.7613 - accuracy: 0.6348 - val_loss: 0.5979 - val_accuracy: 0.6484\n",
            "Epoch 114/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6562 - accuracy: 0.6802 - val_loss: 0.5803 - val_accuracy: 0.7143\n",
            "Epoch 115/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6541 - accuracy: 0.6459 - val_loss: 0.5907 - val_accuracy: 0.6703\n",
            "Epoch 116/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5572 - accuracy: 0.7413 - val_loss: 0.6035 - val_accuracy: 0.6703\n",
            "Epoch 117/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6453 - accuracy: 0.6903 - val_loss: 0.5885 - val_accuracy: 0.6593\n",
            "Epoch 118/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6052 - accuracy: 0.6824 - val_loss: 0.5798 - val_accuracy: 0.7143\n",
            "Epoch 119/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6431 - accuracy: 0.7044 - val_loss: 0.5894 - val_accuracy: 0.6923\n",
            "Epoch 120/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6458 - accuracy: 0.7287 - val_loss: 0.6281 - val_accuracy: 0.6484\n",
            "Epoch 121/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6183 - accuracy: 0.6605 - val_loss: 0.5664 - val_accuracy: 0.6813\n",
            "Epoch 122/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.6663 - accuracy: 0.6612 - val_loss: 0.5535 - val_accuracy: 0.7253\n",
            "Epoch 123/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6799 - accuracy: 0.6434 - val_loss: 0.5815 - val_accuracy: 0.6703\n",
            "Epoch 124/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6011 - accuracy: 0.6836 - val_loss: 0.6265 - val_accuracy: 0.6593\n",
            "Epoch 125/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6546 - accuracy: 0.6923 - val_loss: 0.6373 - val_accuracy: 0.6154\n",
            "Epoch 126/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6108 - accuracy: 0.6346 - val_loss: 0.5649 - val_accuracy: 0.6813\n",
            "Epoch 127/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5835 - accuracy: 0.6849 - val_loss: 0.5703 - val_accuracy: 0.6813\n",
            "Epoch 128/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6136 - accuracy: 0.6963 - val_loss: 0.5594 - val_accuracy: 0.7033\n",
            "Epoch 129/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6217 - accuracy: 0.6726 - val_loss: 0.5656 - val_accuracy: 0.7143\n",
            "Epoch 130/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6474 - accuracy: 0.6781 - val_loss: 0.5874 - val_accuracy: 0.6813\n",
            "Epoch 131/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5850 - accuracy: 0.7121 - val_loss: 0.5995 - val_accuracy: 0.6593\n",
            "Epoch 132/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5139 - accuracy: 0.7845 - val_loss: 0.5838 - val_accuracy: 0.6813\n",
            "Epoch 133/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5998 - accuracy: 0.7148 - val_loss: 0.5511 - val_accuracy: 0.7143\n",
            "Epoch 134/200\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.6347 - accuracy: 0.6891 - val_loss: 0.5569 - val_accuracy: 0.6923\n",
            "Epoch 135/200\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.6144 - accuracy: 0.6803 - val_loss: 0.5883 - val_accuracy: 0.6593\n",
            "Epoch 136/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5884 - accuracy: 0.6840 - val_loss: 0.5872 - val_accuracy: 0.6593\n",
            "Epoch 137/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6071 - accuracy: 0.6986 - val_loss: 0.6040 - val_accuracy: 0.6484\n",
            "Epoch 138/200\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.6542 - accuracy: 0.6753 - val_loss: 0.5925 - val_accuracy: 0.6593\n",
            "Epoch 139/200\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.6195 - accuracy: 0.6831 - val_loss: 0.5623 - val_accuracy: 0.6813\n",
            "Epoch 140/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.5464 - accuracy: 0.7278 - val_loss: 0.5604 - val_accuracy: 0.6813\n",
            "Epoch 141/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6306 - accuracy: 0.6912 - val_loss: 0.5666 - val_accuracy: 0.6703\n",
            "Epoch 142/200\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.6364 - accuracy: 0.6791 - val_loss: 0.5566 - val_accuracy: 0.6923\n",
            "Epoch 143/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5185 - accuracy: 0.7300 - val_loss: 0.5593 - val_accuracy: 0.6703\n",
            "Epoch 144/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6054 - accuracy: 0.6983 - val_loss: 0.5557 - val_accuracy: 0.6923\n",
            "Epoch 145/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5736 - accuracy: 0.7149 - val_loss: 0.5489 - val_accuracy: 0.7033\n",
            "Epoch 146/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5580 - accuracy: 0.7025 - val_loss: 0.5496 - val_accuracy: 0.7033\n",
            "Epoch 147/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5657 - accuracy: 0.6757 - val_loss: 0.5507 - val_accuracy: 0.6813\n",
            "Epoch 148/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5881 - accuracy: 0.7006 - val_loss: 0.5469 - val_accuracy: 0.7033\n",
            "Epoch 149/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5707 - accuracy: 0.7022 - val_loss: 0.5427 - val_accuracy: 0.7033\n",
            "Epoch 150/200\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5759 - accuracy: 0.7016 - val_loss: 0.5781 - val_accuracy: 0.6703\n",
            "Epoch 151/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5749 - accuracy: 0.7061 - val_loss: 0.5536 - val_accuracy: 0.7253\n",
            "Epoch 152/200\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5463 - accuracy: 0.7132 - val_loss: 0.5417 - val_accuracy: 0.6923\n",
            "Epoch 153/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5726 - accuracy: 0.6883 - val_loss: 0.5744 - val_accuracy: 0.6703\n",
            "Epoch 154/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6017 - accuracy: 0.7020 - val_loss: 0.5428 - val_accuracy: 0.7033\n",
            "Epoch 155/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5570 - accuracy: 0.7020 - val_loss: 0.5995 - val_accuracy: 0.6484\n",
            "Epoch 156/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6205 - accuracy: 0.6379 - val_loss: 0.5740 - val_accuracy: 0.7143\n",
            "Epoch 157/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5576 - accuracy: 0.7237 - val_loss: 0.5473 - val_accuracy: 0.6923\n",
            "Epoch 158/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5968 - accuracy: 0.6927 - val_loss: 0.5456 - val_accuracy: 0.7143\n",
            "Epoch 159/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5612 - accuracy: 0.7266 - val_loss: 0.5481 - val_accuracy: 0.7033\n",
            "Epoch 160/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5823 - accuracy: 0.7228 - val_loss: 0.5628 - val_accuracy: 0.6813\n",
            "Epoch 161/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5831 - accuracy: 0.7147 - val_loss: 0.5514 - val_accuracy: 0.6923\n",
            "Epoch 162/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5481 - accuracy: 0.7093 - val_loss: 0.5528 - val_accuracy: 0.7033\n",
            "Epoch 163/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.5428 - accuracy: 0.6816 - val_loss: 0.5361 - val_accuracy: 0.6923\n",
            "Epoch 164/200\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.5329 - accuracy: 0.7113 - val_loss: 0.5302 - val_accuracy: 0.7033\n",
            "Epoch 165/200\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.5570 - accuracy: 0.7045 - val_loss: 0.5320 - val_accuracy: 0.6923\n",
            "Epoch 166/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5290 - accuracy: 0.7514 - val_loss: 0.5475 - val_accuracy: 0.7143\n",
            "Epoch 167/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5665 - accuracy: 0.7003 - val_loss: 0.5483 - val_accuracy: 0.6923\n",
            "Epoch 168/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.5681 - accuracy: 0.7106 - val_loss: 0.5823 - val_accuracy: 0.6923\n",
            "Epoch 169/200\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5425 - accuracy: 0.7645 - val_loss: 0.6440 - val_accuracy: 0.6484\n",
            "Epoch 170/200\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.6236 - accuracy: 0.6526 - val_loss: 0.5616 - val_accuracy: 0.7253\n",
            "Epoch 171/200\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.5479 - accuracy: 0.7656 - val_loss: 0.5544 - val_accuracy: 0.7033\n",
            "Epoch 172/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5902 - accuracy: 0.6953 - val_loss: 0.5463 - val_accuracy: 0.7033\n",
            "Epoch 173/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5571 - accuracy: 0.7352 - val_loss: 0.5412 - val_accuracy: 0.7143\n",
            "Epoch 174/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6141 - accuracy: 0.6450 - val_loss: 0.5465 - val_accuracy: 0.6813\n",
            "Epoch 175/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5456 - accuracy: 0.7566 - val_loss: 0.5471 - val_accuracy: 0.7253\n",
            "Epoch 176/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5705 - accuracy: 0.7093 - val_loss: 0.5557 - val_accuracy: 0.6923\n",
            "Epoch 177/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5927 - accuracy: 0.6925 - val_loss: 0.5581 - val_accuracy: 0.7143\n",
            "Epoch 178/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6353 - accuracy: 0.6798 - val_loss: 0.5394 - val_accuracy: 0.7253\n",
            "Epoch 179/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6004 - accuracy: 0.7352 - val_loss: 0.5385 - val_accuracy: 0.6923\n",
            "Epoch 180/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5633 - accuracy: 0.7168 - val_loss: 0.5310 - val_accuracy: 0.7143\n",
            "Epoch 181/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5711 - accuracy: 0.7225 - val_loss: 0.5333 - val_accuracy: 0.6813\n",
            "Epoch 182/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5104 - accuracy: 0.7132 - val_loss: 0.5378 - val_accuracy: 0.7253\n",
            "Epoch 183/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5226 - accuracy: 0.7779 - val_loss: 0.5349 - val_accuracy: 0.7143\n",
            "Epoch 184/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5538 - accuracy: 0.7461 - val_loss: 0.5378 - val_accuracy: 0.7253\n",
            "Epoch 185/200\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5958 - accuracy: 0.6889 - val_loss: 0.5423 - val_accuracy: 0.7033\n",
            "Epoch 186/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.5985 - accuracy: 0.7182 - val_loss: 0.5613 - val_accuracy: 0.7143\n",
            "Epoch 187/200\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.6134 - accuracy: 0.7197 - val_loss: 0.5579 - val_accuracy: 0.7033\n",
            "Epoch 188/200\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.5403 - accuracy: 0.7184 - val_loss: 0.5732 - val_accuracy: 0.7143\n",
            "Epoch 189/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6257 - accuracy: 0.6832 - val_loss: 0.5388 - val_accuracy: 0.7253\n",
            "Epoch 190/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5374 - accuracy: 0.7301 - val_loss: 0.5421 - val_accuracy: 0.7033\n",
            "Epoch 191/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5102 - accuracy: 0.7734 - val_loss: 0.5524 - val_accuracy: 0.7033\n",
            "Epoch 192/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5595 - accuracy: 0.7352 - val_loss: 0.5309 - val_accuracy: 0.7033\n",
            "Epoch 193/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6061 - accuracy: 0.6839 - val_loss: 0.5522 - val_accuracy: 0.6813\n",
            "Epoch 194/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5503 - accuracy: 0.7255 - val_loss: 0.5276 - val_accuracy: 0.7143\n",
            "Epoch 195/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5057 - accuracy: 0.7770 - val_loss: 0.5252 - val_accuracy: 0.7143\n",
            "Epoch 196/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5129 - accuracy: 0.7397 - val_loss: 0.5328 - val_accuracy: 0.7473\n",
            "Epoch 197/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5748 - accuracy: 0.7415 - val_loss: 0.5416 - val_accuracy: 0.7363\n",
            "Epoch 198/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5075 - accuracy: 0.7484 - val_loss: 0.5551 - val_accuracy: 0.6703\n",
            "Epoch 199/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5612 - accuracy: 0.7104 - val_loss: 0.5300 - val_accuracy: 0.7143\n",
            "Epoch 200/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5793 - accuracy: 0.6802 - val_loss: 0.5361 - val_accuracy: 0.7253\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x1fc0a182788>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('model.h5') # save model weights"
      ]
    },
    {
      "source": [
        "**Step 5: Make a Prediction**"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.60580647]\n [0.65303326]\n [0.23911962]\n [0.7100071 ]\n [0.621463  ]\n [0.3503753 ]\n [0.8140195 ]\n [0.6142649 ]\n [0.5169017 ]\n [0.31914288]\n [0.3649218 ]\n [0.6120107 ]\n [0.80846965]\n [0.77108586]\n [0.82776433]\n [0.32369396]\n [0.83750165]\n [0.9392719 ]\n [0.21492794]\n [0.614543  ]\n [0.47905293]\n [0.7846843 ]\n [0.52737135]\n [0.86580694]\n [0.8071549 ]\n [0.18306628]\n [0.593039  ]\n [0.1634939 ]\n [0.73569703]\n [0.9218981 ]\n [0.00752011]\n [0.50071806]\n [0.38067368]\n [0.46352386]\n [0.47699687]\n [0.23800167]\n [0.36078542]\n [0.87008095]\n [0.3634832 ]\n [0.06144667]\n [0.79864717]\n [0.4481297 ]\n [0.7105988 ]\n [0.18225664]\n [0.94360685]\n [0.88607633]\n [0.8062229 ]\n [0.7994201 ]\n [0.59960365]\n [0.73373294]\n [0.87179506]\n [0.7686721 ]\n [0.74767166]\n [0.8300034 ]\n [0.18632382]\n [0.66968757]\n [0.02863985]\n [0.43708792]\n [0.16221261]\n [0.67217636]\n [0.45392418]\n [0.06043327]\n [0.66121304]\n [0.61546457]\n [0.7847743 ]\n [0.6222504 ]\n [0.82438767]\n [0.8396523 ]\n [0.4223587 ]\n [0.8605566 ]\n [0.49826866]\n [0.35219586]\n [0.7017589 ]\n [0.8104245 ]\n [0.06551176]\n [0.6756201 ]\n [0.9225117 ]\n [0.13005015]\n [0.94300836]\n [0.5161081 ]\n [0.80399907]\n [0.61001563]\n [0.42836598]\n [0.8019196 ]\n [0.5732519 ]\n [0.59539485]\n [0.8325971 ]\n [0.77321464]\n [0.5060555 ]\n [0.8778746 ]\n [0.04767755]]\n"
          ]
        }
      ],
      "source": [
        "result = model.predict(X_test)\n",
        "print(result)"
      ]
    }
  ]
}
